{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3aa6359-fae6-42a1-bd71-e9d1f0aa7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader\n",
    ")\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from skimage import io\n",
    "from transformers import ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from transformers import ConvNextFeatureExtractor, ConvNextForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516c3fb4-c606-4939-858d-68601787c044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cultivar</th>\n",
       "      <th>cultivar_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000005362.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000099707.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000135300.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000136796.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000292439.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23634</th>\n",
       "      <td>999578153.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23635</th>\n",
       "      <td>999692877.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23636</th>\n",
       "      <td>999756998.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23637</th>\n",
       "      <td>999892248.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23638</th>\n",
       "      <td>999945922.png</td>\n",
       "      <td>PI_152923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23639 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename   cultivar  cultivar_index\n",
       "0      1000005362.png  PI_152923               0\n",
       "1      1000099707.png  PI_152923               0\n",
       "2      1000135300.png  PI_152923               0\n",
       "3      1000136796.png  PI_152923               0\n",
       "4      1000292439.png  PI_152923               0\n",
       "...               ...        ...             ...\n",
       "23634   999578153.png  PI_152923               0\n",
       "23635   999692877.png  PI_152923               0\n",
       "23636   999756998.png  PI_152923               0\n",
       "23637   999892248.png  PI_152923               0\n",
       "23638   999945922.png  PI_152923               0\n",
       "\n",
       "[23639 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basedir = os.getcwd()\n",
    "datadir = basedir + '/data'\n",
    "# reading the csv file with annotated image file names\n",
    "test_cultivar= pd.read_csv(datadir + '/sample_submission.csv')\n",
    "test_cultivar.dropna(inplace=True)\n",
    "\n",
    "# creating list of unique cultivars\n",
    "labels=list(np.unique(test_cultivar['cultivar']))\n",
    "\n",
    "# turning cultivar labels into strings\n",
    "test_cultivar['cultivar']=test_cultivar['cultivar'].astype(str)\n",
    "test_cultivar[\"cultivar_index\"] = test_cultivar[\"cultivar\"].map(lambda item: labels.index(item))\n",
    "\n",
    "test_cultivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d6162b-c995-420b-ba10-9d1dd664d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = basedir + '/results/vit/checkpoint-300'\n",
    "#feature_extractor = ConvNextFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "\n",
    "# building feature extractor to grab labels\n",
    "class FeatureExtractor(object):\n",
    "    def __call__(self, image, target):\n",
    "        sample = feature_extractor(image, return_tensors='pt')\n",
    "        sample[\"labels\"] = target\n",
    "        return sample\n",
    "\n",
    "class CultivarDataset(Dataset):\n",
    "    def __init__(self, df_img, df_label, transform):\n",
    "        self.labels = df_label\n",
    "        self.image_path = df_img\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = datadir + '/test/' + self.image_path[idx]\n",
    "        image = io.imread(image_path)\n",
    "        \n",
    "        y_label = torch.tensor(int(self.labels.iloc[idx]))\n",
    "       # y_label = int(self.labels.iloc[idx])\n",
    "        \n",
    "        data = self.transform(image,y_label)\n",
    "        data['pixel_values'] = torch.squeeze(data['pixel_values'])\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c592dc3-6a07-450a-ba18-064803c20f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CultivarDataset(\n",
    "    df_img = test_cultivar['filename'],\n",
    "    df_label = test_cultivar['cultivar_index'],\n",
    "    transform = FeatureExtractor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55513df3-c605-47cf-902a-313e81f434e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[-1.0733, -0.9363, -0.9705,  ..., -1.1589, -1.1418, -1.1589],\n",
       "         [-0.9705, -0.9363, -0.9534,  ..., -1.1589, -1.1760, -1.1760],\n",
       "         [-1.0390, -1.0390, -0.8335,  ..., -1.0562, -1.0904, -1.1075],\n",
       "         ...,\n",
       "         [-0.9705, -1.0219, -1.1247,  ..., -0.6452, -0.6794, -0.8678],\n",
       "         [-1.1418, -1.1760, -1.2617,  ..., -0.7308, -0.9877, -1.0562],\n",
       "         [-1.3130, -1.3130, -1.3815,  ...,  0.2796,  0.1426,  0.1768]],\n",
       "\n",
       "        [[-0.9503, -0.8277, -0.8277,  ..., -0.9853, -0.9853, -1.0028],\n",
       "         [-0.8627, -0.7927, -0.8277,  ..., -1.0378, -1.0378, -1.0553],\n",
       "         [-0.9328, -0.9503, -0.7402,  ..., -0.8978, -0.9328, -0.9678],\n",
       "         ...,\n",
       "         [-0.7752, -0.8102, -0.9153,  ..., -0.3901, -0.5126, -0.7052],\n",
       "         [-1.0028, -1.0553, -1.1253,  ..., -0.5651, -0.7927, -0.8277],\n",
       "         [-1.1779, -1.2304, -1.2654,  ...,  0.4678,  0.3627,  0.3803]],\n",
       "\n",
       "        [[-1.0027, -0.9156, -0.8807,  ..., -1.0027, -0.9678, -1.0027],\n",
       "         [-0.9156, -0.8110, -0.8284,  ..., -1.0201, -1.0376, -1.0376],\n",
       "         [-0.9330, -0.9156, -0.7761,  ..., -0.9504, -0.9853, -0.9853],\n",
       "         ...,\n",
       "         [-0.7761, -0.8458, -0.9330,  ..., -0.6018, -0.6890, -0.8458],\n",
       "         [-0.9853, -1.0376, -1.0898,  ..., -0.7238, -0.8633, -0.8633],\n",
       "         [-1.1247, -1.1596, -1.1596,  ..., -0.1138, -0.2010, -0.1487]]]), 'labels': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6360031-180a-40f5-816f-625398a1bd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_ds.__getitem__(9)['pixel_values']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1966431-c40b-4b4f-982a-17b879cb18b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 23639\n",
      "  Batch size = 32\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='83' max='739' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 83/739 03:49 < 30:37, 0.36 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "#model = ConvNextForImageClassification.from_pretrained(model_name_or_path)\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "        model_name_or_path\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model\n",
    ")\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "pred = trainer.predict(test_ds).predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "90d4cfff-8412-42bb-a816-8c84ecfba694",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(basedir + '/mod1predictions','w') as f:\n",
    "        for row in labels:\n",
    "            f.write(str(row))\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1be05554-91dc-4ab7-9d19-ccbf48d4e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# softmax each row so each row sums to 1\n",
    "prob = softmax(pred, axis = 1)\n",
    "culti_index = np.argmax(prob,axis =1)\n",
    "\n",
    "with open(basedir + '/mod1predictions','w') as f:\n",
    "        for row in prob:\n",
    "            f.write(str(row))\n",
    "            f.write('\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "0f7ea756-f12d-4ff4-8fe6-a418816c1e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_cultivar['cultivar_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9b6f13a9-a7d0-4f6b-9207-67bec579b0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52, 93, 61, ..., 22, 18, 67])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f58525ce-069f-4b0a-8a04-2bda504d06e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the csv file with annotated image file names\n",
    "train_cultivar= pd.read_csv(datadir + '/train_cultivar_mapping.csv')\n",
    "train_cultivar.dropna(inplace=True)\n",
    "\n",
    "# turning cultivar labels into strings\n",
    "train_cultivar['cultivar']=train_cultivar['cultivar'].astype(str)\n",
    "\n",
    "# creating list of unique cultivars\n",
    "labels=list(np.unique(train_cultivar['cultivar']))\n",
    "\n",
    "# encoding cultivar_index column\n",
    "train_cultivar[\"cultivar_index\"] = train_cultivar[\"cultivar\"].map(lambda item:\n",
    "            labels.index(item))\n",
    "\n",
    "# building label and id dicts\n",
    "label2id, id2label = dict(), dict()\n",
    "for i,label in enumerate(labels):\n",
    "    label2id[label]=str(i)\n",
    "    id2label[str(i)]=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "10c5c822-7dec-4545-88bf-8a1258c085a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for val in y_pred:\n",
    "    key_val = str(val)\n",
    "    labels.append(id2label[key_val])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6d95e456-a9fb-4596-852e-806d2b218c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['filename'] = test_cultivar['filename']\n",
    "submission['cultivar'] = labels\n",
    "submission.drop([0])\n",
    "submission.to_csv(basedir+'/mod1submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a6362e8b-38da-4ef0-874c-329514834fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4439\n",
      "  Batch size = 24\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_cultivar['image'],train_cultivar[\"cultivar_index\"], test_size = 0.2)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# valid dataset\n",
    "valid_ds = CultivarDataset(\n",
    "    df_img = X_test,\n",
    "    df_label = y_test,\n",
    "    transform=FeatureExtractor(),\n",
    ")\n",
    "valid_pred = trainer.predict(valid_ds).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deca4fd9-dbb6-4058-8b77-6793cac944e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
